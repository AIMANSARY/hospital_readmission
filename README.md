# Hospital Readmission Prediction using Feature-Store-Driven ML Pipeline

## Project Overview
Hospital readmissions within 30 days are a major challenge for healthcare systems, impacting patient outcomes and operational costs.  
This project implements an **end-to-end machine learning pipeline** to predict hospital readmissions using a **feature-store-based architecture**, multiple models, and systematic evaluation.

The pipeline is designed to be **modular, reproducible, and extensible**, following best practices in data engineering and applied machine learning.

---

## Objectives
- Build a **feature-store-driven data pipeline** for hospital readmission prediction
- Compare multiple machine learning models on the same feature set
- Identify the most influential clinical features driving readmission risk
- Analyze model trade-offs relevant to real-world healthcare decision-making

---

## Research Questions Addressed

### **RQ1**
**How effectively can a feature-store-based pipeline improve hospital readmission prediction?**

Answered by comparing multiple machine learning models trained on the same engineered feature set.

---

### **RQ2**
**Which clinical features contribute most strongly to readmission risk?**

Answered using Random Forest feature importance analysis.

---

### **RQ3**
**How does model choice affect the trade-off between precision and recall in hospital readmission prediction?**

Answered through metric comparison and a precision–recall visualization.

---

## **Project Structure**

 ```text
hospital_readmission/
│
├── data/                          # All datasets used in the pipeline
│   ├── raw/                       # Original raw dataset (unchanged)
│   ├── cleaned/                   # Cleaned dataset after preprocessing
│   └── processed/                 # Feature-store-ready dataset used by models
│
├── src/                           # Source code for the ML pipeline
│   ├── feature_engineering/
│   │   └── build_features.py      # Creates reusable, model-ready features
│   │
│   ├── modeling/
│   │   ├── train_model.py         # Trains baseline Logistic Regression model
│   │   ├── compare_models.py      # Compares Logistic Regression vs Random Forest (RQ1)
│   │   └── feature_importance.py  # Extracts Random Forest feature importance (RQ2)
│   │
│   └── evaluation/
│       └── rq3_precision_recall_plot.py
│                                   # Generates precision–recall comparison figure (RQ3)
│
├── dags/
│   └── project_pipeline_dag.py    # Airflow DAG defining the end-to-end pipeline
│
├── tables/                        # Tabular results generated by the pipeline
│   ├── baseline_model_metrics.csv # Metrics for baseline Logistic Regression
│   ├── model_comparison_metrics.csv
│   │                               # Model comparison metrics (RQ1)
│   └── feature_importance_rf.csv  # Feature importance scores (RQ2)
│
├── figures/                       # Visual outputs for analysis and reporting
│   ├── model_comparison_roc.png   # ROC curve comparison of models (RQ1)
│   ├── feature_importance_rf.png  # Top clinical features driving readmission (RQ2)
│   └── precision_recall_comparison.png
│                                   # Precision vs Recall comparison (RQ3)
│
├── venv/                          # Python virtual environment (not committed)
│
├── README.md                      # Project documentation
└── requirements.txt               # Python dependencies

 ```


---

## Methodology

### 1️. Data Processing & Feature Store
- Raw hospital data is cleaned and standardized
- Feature engineering creates reusable, model-ready features
- The processed dataset functions as a **feature store** for all models

---

### 2️. Model Training
Two models were trained using the same feature store:
- Logistic Regression (baseline, interpretable)
- Random Forest (non-linear, higher capacity)

---

### 3️. Model Evaluation (RQ1)
Metrics used:
- Accuracy
- Precision
- Recall
- F1-score
- ROC-AUC

Results:
- `tables/model_comparison_metrics.csv`
- `figures/model_comparison_roc.png`

---

### 4️. Feature Importance (RQ2)
- Random Forest feature importance used to identify key clinical drivers
- Highlights the most influential clinical and demographic features

Outputs:
- `tables/feature_importance_rf.csv`
- `figures/feature_importance_rf.png`

---

### 5️. Precision–Recall Trade-off Analysis (RQ3)
- Comparison of precision and recall across models
- Demonstrates model selection trade-offs in healthcare contexts

Output:
- `figures/precision_recall_comparison.png`

---

## Key Findings
- Feature-store-based pipelines enable consistent and fair model comparison
- Logistic Regression achieves higher precision
- Random Forest achieves higher recall and F1-score
- Readmission risk is influenced by multiple clinical and demographic factors
- Model choice should align with clinical priorities such as patient safety or cost efficiency

---

## Technologies Used
- Python
- Pandas, NumPy
- Scikit-learn
- Matplotlib
- Apache Airflow (DAG design)
- Git & GitHub

---

## How to Run

```bash
# Activate virtual environment
venv\Scripts\activate

# Feature engineering
python -c "from src.feature_engineering.build_features import engineer_features; engineer_features()"

# Train baseline model
python -c "from src.modeling.train_model import train_model; train_model()"

# Compare models
python -c "from src.modeling.compare_models import compare_models; compare_models()"

# Feature importance
python -c "from src.modeling.feature_importance import generate_feature_importance; generate_feature_importance()"

# RQ3 figure
python -c "from src.evaluation.rq3_precision_recall_plot import plot_precision_recall; plot_precision_recall()"

 ```
---

## Conclusion

This project demonstrates how a feature-store-driven machine learning pipeline can support robust experimentation, model comparison, and explainability in healthcare prediction tasks. The results highlight important performance trade-offs and provide actionable insights for hospital readmission risk management.


